# ğŸ“° Noticias BBC - Web Scraper con Playwright

Este proyecto es un **web scraper en Python** que extrae titulares, descripciones y enlaces de artÃ­culos de la secciÃ³n **Culture** de BBC.  
Los datos se almacenan en un archivo CSV para facilitar su anÃ¡lisis y uso posterior.

---

## ğŸš€ TecnologÃ­as usadas
- [Python 3.10+](https://www.python.org/)  
- [Playwright](https://playwright.dev/python/) (automatizaciÃ³n de navegador)  
- [Pandas](https://pandas.pydata.org/) (procesamiento y exportaciÃ³n de datos)  
- [Rich](https://github.com/Textualize/rich) (logs con formato)  

---

## ğŸ“‚ Estructura del proyecto
```

noticias-bbc/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ contexto.py
â”‚   â”œâ”€â”€ simulacion.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ noticias\_bbc.csv
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

````

---

## âš™ï¸ InstalaciÃ³n
1. Clona el repositorio:
   ```bash
   git clone https://github.com/tu_usuario/noticias-bbc.git
   cd noticias-bbc
````

2. Crea un entorno virtual e instala las dependencias:

   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac
   venv\Scripts\activate      # Windows

   pip install -r requirements.txt
   ```

3. Instala los navegadores de Playwright:

   ```bash
   playwright install
   ```

---

## â–¶ï¸ Uso

Ejecuta el scraper:

```bash
python src/main.py
```

Esto generarÃ¡ un archivo CSV en la carpeta `data/` con el siguiente formato:

| titulo               | descripcion              | urls                                                                            |
| -------------------- | ------------------------ | ------------------------------------------------------------------------------- |
| Ejemplo de titular 1 | Ejemplo de descripciÃ³n 1 | [https://www.bbc.com/culture/article/](https://www.bbc.com/culture/article/)... |
| Ejemplo de titular 2 | Ejemplo de descripciÃ³n 2 | [https://www.bbc.com/culture/article/](https://www.bbc.com/culture/article/)... |

---

## ğŸ“Œ Notas

* Se bloquean imÃ¡genes durante la navegaciÃ³n para **acelerar la carga**.
* Se implementa **logging** para seguimiento de errores y eventos importantes.
* Las URLs son filtradas para incluir Ãºnicamente artÃ­culos relevantes.

---

## ğŸ“„ Licencia

Este proyecto se distribuye bajo la licencia MIT.

```

